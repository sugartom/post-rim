docker run --gpus device=0 -it -v /tmp:/tmp tensorflow/tensorflow:1.13.0rc1-gpu

saved_model_cli convert --dir /tmp/ssd_inception/1 --output_dir /tmp/ssd_inception32/1 --tag_set serve tensorrt --precision_mode FP32 --max_batch_size 1 --is_dynamic_op True
saved_model_cli convert --dir /tmp/ssd_inception/1 --output_dir /tmp/ssd_inception16/1 --tag_set serve tensorrt --precision_mode FP16 --max_batch_size 1 --is_dynamic_op True
saved_model_cli convert --dir /tmp/ssd_inception/1 --output_dir /tmp/ssd_inception8/1 --tag_set serve tensorrt --precision_mode INT8 --max_batch_size 1 --is_dynamic_op True

docker run --gpus all --cpuset-cpus 0-6 -it -p 50101:50101 --name container-serving1 -v ~/Downloads/tmp/docker-share:/home/yitao/Downloads/tmp/docker-share sugartom/edge-publish:rim-test
tensorflow_model_server --port=8500 --model_name=ssd_inception_v2_coco --model_base_path=/home/yitao/Downloads/tmp/docker-share/trt_test/ssd_inception >out-001 2>&1 &
python tom_test_batch_graph.py
